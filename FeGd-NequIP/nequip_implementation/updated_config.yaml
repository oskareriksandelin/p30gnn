# ===========
#     RUN
# ===========
# the run types will be completed in sequence
# one can do `train`, `val`, `test` run types
run: [train, test]

# data and model r_max can be different (model's r_max should be smaller), but we try to make them the same
cutoff_radius: 5.0

# variable interpolation is convenient for wandb sweeps, see documentation for more details
# the following are NequIP model hyperparameters that can be swept over
num_layers: 4       # number of interaction blocks, we find 3-5 to work best
l_max: 1            # the maximum irrep order (rotation order) for the network's features, l=1 is a good default, l=2 is more accurate but slower
num_features: 32    # the multiplicity of the features, 32 is a good default for accurate network, if you want to be more accurate, go larger, if you want to be faster, go lower

# There are two sets of atomic types to keep track of in most applications.
# There is the conventional atomic species (e.g. C, H), and a separate `type_names` known to the model.
# The model only knows types based on a set of zero-based indices and user-given `type_names` argument.
# An example where this distinction is necessary include datasets with the same atomic species with different charge states:
# we could define `chemical_species: [C, C]` and model `type_names: [C3, C4]` for +3 and +4 charge states.
# There could also be instances such as coarse graining we only care about the model's `type_names` (no need to define chemical species).
# Because of this distinction, these variables show up as arguments across different categories, including, data, model, metrics and even callbacks.
# In this case, we fix both to be the same, so we define a single set of each here and use variable interpolation to retrieve them below.
# This ensures a single location where the values are set to reduce the chances of misconfiguring runs.
model_type_names: [Fe, Gd]
chemical_species: ${model_type_names}

# We want a metric to condition training on (e.g. for best `ModelCheckpoint`, `EarlyStopping`, LR scheduling) which will show up in various places later on, so we set up a "single source of truth" to interpolate over
# see https://nequip.readthedocs.io/en/latest/guide/configuration/metrics.html
monitored_metric: val0_epoch/weighted_sum # CHANGE THIS

# ============
#     DATA
# ============
# New users are advised to read the "Data Configuration" docs before continuing: https://nequip.readthedocs.io/en/latest/guide/configuration/data.html
data:
  _target_: nequip.data.datamodule.ASEDataModule
  seed: 456             # dataset seed for reproducibility

  # here we take an ASE-readable file (in extxyz format) and split it into train:val:test = 80:10:10
  split_dataset:
    file_path: ../../data/fegd_dataset.xyz
    train: 0.8
    val: 0.1
    test: 0.1
  
  # `transforms` convert data from the Dataset to a form that can be used by the ML model
  transforms:
    # the models only know atom types, which can be different from the chemical species (e.g. C, H)
    # in this case, the atom types are the same as the chemical species (H, C, O, Cu), so we can omit
    # `chemical_species_to_atom_type_map` and it will default to an identity mapping
    # if `model_type_names` were something like ["my_H", "carbon", "oxygen", "copper"], then you would need
    # to explicitly provide the mapping: chemical_species_to_atom_type_map: {H: my_H, C: carbon, O: oxygen, Cu: copper}
    - _target_: nequip.data.transforms.ChemicalSpeciesToAtomTypeMapper
      model_type_names: ${model_type_names}
      # chemical_species_to_atom_type_map: ${list_to_identity_dict:${chemical_species}}
    # data doesn't usually come with a neighborlist -- this transform prepares the neighborlist
    - _target_: nequip.data.transforms.NeighborListTransform
      r_max: ${cutoff_radius}

  # the following are torch.utils.data.DataLoader configs,
  # excluding the arguments `dataset` and `collate_fn`
  # https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader
  train_dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 8
    num_workers: 0
    shuffle: false
  val_dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 16
    num_workers: ${data.train_dataloader.num_workers}  # we want to use the same num_workers -- variable interpolation helps
  test_dataloader: ${data.val_dataloader}  # variable interpolation comes in handy again

  # dataset statistics can be calculated to be used for model initialization such as for shifting, scaling and standardizing.
  # it is advised to provide custom names -- you will have to retrieve them later under model to initialize certain parameters to the dataset statistics computed
  stats_manager:
    # dataset statistics is handled by the `DataStatisticsManager`
    # here, we use `CommonDataStatisticsManager` for a basic set of dataset statistics for general use cases
    # the dataset statistics include `num_neighbors_mean`, `per_atom_energy_mean`, `forces_rms`, `per_type_forces_rms`
    _target_: nequip.data.CommonDataStatisticsManager # CHANGE THIS
    # dataloader kwargs for data statistics computation
    # `batch_size` should ideally be as large as possible without triggering OOM
    dataloader_kwargs:
      batch_size: 10
    # we need to provide the same type names that correspond to the model's `type_names`
    # so we interpolate the "central source of truth" model type names from above
    type_names: ${model_type_names}
  
# =============
#    TRAINER
# =============
# `trainer` is a `Lightning.Trainer` object (https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api)
trainer:
  _target_: lightning.Trainer
  accelerator: gpu
  enable_checkpointing: true
  max_epochs: 20
  max_time: 00:10:00:00
  log_every_n_steps: 5       # how often to log

  # use any Lightning supported logger
  logger:
    # Lightning wandb logger https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.wandb.html#module-lightning.pytorch.loggers.wandb
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    project: nequip
    name: tutorial
    save_dir: ${hydra:runtime.output_dir}  # use resolver to place wandb logs in hydra's output directory

  # use any Lightning callbacks https://lightning.ai/docs/pytorch/stable/api_references.html#callbacks
  # and any custom callbacks that subclass Lightning's Callback parent class
  callbacks:

    # https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.pytorch.callbacks.EarlyStopping
    - _target_: lightning.pytorch.callbacks.EarlyStopping
      monitor: ${monitored_metric}            # validation metric to monitor
      min_delta: 1e-3                         # how much to be considered a "change"
      patience: 20                            # how many instances of "no change" before stopping

    # https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      monitor: ${monitored_metric}            # validation metric to monitor
      dirpath: ${hydra:runtime.output_dir}    # use hydra output directory
      filename: best                          # `best.ckpt` is the checkpoint name
      save_last: true                         # `last.ckpt` will be saved

    # https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.LearningRateMonitor.html#lightning.pytorch.callbacks.LearningRateMonitor
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: epoch
     
# =====================
#    TRAINING MODULE
# =====================
# training_module refers to a `NequIPLightningModule` or its subclass
# here we use the subclass that holds an exponential moving average of the base model's weights (an EMA model)
# one could also use the base `NequIPLightningModule` here if one does not want to use an EMA model
# EMA allows for smoother validation curves and thus more reliable metrics for monitoring
# Loading from a checkpoint for use in the `nequip.ase.NequIPCalculator` or during `nequip-compile` and `nequip-package` will always load the EMA model if it's present
training_module:
  _target_: nequip.train.EMALightningModule

  # the ema decay parameter of an EMA model
  ema_decay: 0.999